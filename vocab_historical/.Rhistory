2+2
install.packages('tidyverse')
install.packages('spacyr')
library(ggplot2)
library(quanteda)
d_count <- dfm(data_corpus_inaugural) %>% dfm_weight("count") %>% as.data.frame
d_rel_freq <- dfm(data_corpus_inaugural) %>% dfm_weight("prop") %>% as.data.frame
test_words <- c('the','of','states','will','power','beauty','slavery','time','enchanting')
library(dplyr)
library(ggplot2)
library(quanteda)
d_count <- dfm(data_corpus_inaugural) %>% dfm_weight("count") %>% as.data.frame
library(magrittr)
library(quanteda)
d_count <- dfm(data_corpus_inaugural) %>% dfm_weight("count") %>% as.data.frame
library(quanteda)
install.packages('quanteda')
library(dplyr)
library(ggplot2)
library(magrittr)
library(quanteda)
d_count <- dfm(data_corpus_inaugural) %>% dfm_weight("count") %>% as.data.frame
d_rel_freq <- dfm(data_corpus_inaugural) %>% dfm_weight("prop") %>% as.data.frame
test_words <- c('the','of','states','will','power','beauty','slavery','time','enchanting')
tmp <- select(d_count, test_words)
?select
tmp <- select(d_count, test_words)
shiny::runApp('Dropbox/conceptLab/apps/viewer-0-8')
runApp('Dropbox/Simples/Text Mining/simples_viewer')
library(quanteda)
library(readtext)
library(spacyr)
pubmed_corpus <- readtext('~/Dropbox/data/corpora/pubmed-mini/Camb_Q_Healthc_Ethics/') %>% corpus
spacy_initialize(python_executable = '/home/paul/anaconda3/bin/python')
prsed <- spacy_parse(pubmed_corpus)
View(prsed)
library(quanteda)
library(readtext)
library(spacyr)
pubmed_corpus <- readtext('~/Dropbox/data/corpora/pubmed-mini/Camb_Q_Healthc_Ethics/') %>% corpus
spacy_initialize(python_executable = '/home/paul/anaconda3/bin/python')
prsed <- spacy_parse(pubmed_corpus)
pubmed_corpus_cal <- readtext('~/Dropbox/data/corpora/pubmed-mini/Calcif_Tissue_Int//') %>% corpus
prsed <- spacy_parse(pubmed_corpus_cal)
pubmed_corpus_cal <- readtext('~/Dropbox/data/corpora/pubmed-mini/Calcif_Tissue_Int//') %>% corpus
prsed <- spacy_parse(pubmed_corpus_cal)
named(prsed_cal))
named(prsed_cal)
names(prsed_cal)
View(prsed)
names(prsd_cal)
names(prsd)
names(prsed)
rels <- prsed_cal
rels <- prsed
lemma_freq <- group_by(rels, lemma, rel_type) %>% summarize(count = sum(Freq)) %>% ungroup
library(tidyr)
rels <- prsed
lemma_freq <- group_by(rels, lemma, rel_type) %>% summarize(count = sum(Freq)) %>% ungroup
library(tidyr)
lemma_freq <- group_by(rels, lemma, rel_type) %>% summarize(count = sum(Freq)) %>% ungroup
library(dplyr)
rels <- prsed
lemma_freq <- group_by(rels, lemma, rel_type) %>% summarize(count = sum(Freq)) %>% ungroup
lemma_freq <- group_by(rels, lemma, pos) %>% summarize(count = sum(Freq)) %>% ungroup
prs <- prsed_cal
prs <- prsed
prs$target <- prs[as.numeric(row.names(prs)) + (prs$head_token_id - prs$token_id) ,'lemma']
prs$target <- prs[as.numeric(row.names(prs)) + (prs$head_token_id - prs$token_id) ,'lemma']
tmp <- prs[as.numeric(row.names(prs)) + (prs$head_token_id - prs$token_id) ,'lemma']
View(prs)
prsed <- spacy_parse(pubmed_corpus, dependency = TRUE)
library(readr)
files <- list.files(path)
path <- '~/Dropbox/data/truncated_EEBO_freqs/'
files <- list.files(path)
?list.files
files <- list.files(path, full.names = TRUE)
tmp <- read_table(tiles[[1]])
tmp <- read_table(files[[1]])
View(tmp)
?read_table()
tmp <- read_table(files[[1]], col.names=c('token','freq'))
tmp <- read_table(files[[1]], col_names=c('token','freq'))
View(tmp)
tmp <- read_table2(files[[1]], col_names=c('token','freq'))
View(tmp)
library(dplyr)
library(glmnet)
library(dplyr)
library(feather)
library(ggplot2)
library(quanteda)
library(readtext)
library(spacyr)
library(stringr)
?spacy_initialize
spacy_initialize(python_executable = "/home/paul/anaconda3/bin/python3")
spacy_initialize(python_executable = "/home/paul/anaconda3/bin/python3")
library(devtools)
devtools::install_github("quanteda/spacyr", build_vignettes = FALSE)
devtools::install_github("quanteda/spacyr", build_vignettes = FALSE)
library(dplyr)
library(feather)
library(ggplot2)
library(quanteda)
library(readtext)
library(spacyr)
library(stringr)
spacy_initialize(python_executable = "/home/paul/anaconda3/bin/python3")
shiny::runApp('Dropbox/conceptLab/apps/viewernet-1-0')
?renderDataTable
library(shiny)
?renderDataTable
runApp('Dropbox/conceptLab/apps/viewer-0-9')
?format
shiny::runApp('Dropbox/conceptLab/apps/viewer-0-9')
runApp('Dropbox/conceptLab/apps/viewer-0-9')
?scatterplotThreeOutput
runApp('Dropbox/conceptLab/apps/viewer-0-9')
runApp('Dropbox/conceptLab/apps/viewer-0-9')
View(conc)
runApp('Dropbox/conceptLab/apps/viewer-0-9')
?tabsetPanel
library(shiny)
?tabsetPanel
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
runApp('Dropbox/conceptLab/apps/viewernet-1')
install.packages(c("bibliometrix", "broom", "callr", "car", "caTools", "cowplot", "data.table", "dbplyr", "digest", "dplyr", "evaluate", "fpc", "ggplot2", "ggpubr", "glue", "haven", "highr", "httpuv", "igraph", "ISOcodes", "kernlab", "later", "lme4", "maptools", "mclust", "modeltools", "munsell", "ndjson", "openssl", "pillar", "pkgconfig", "purrr", "quanteda", "RcppArmadillo", "RcppParallel", "RCurl", "reprex", "rjson", "rlang", "rmarkdown", "robustbase", "Rttf2pt1", "scales", "shiny", "statnet.common", "streamR", "stringdist", "stringi", "sys", "tidyr", "tinytex", "trimcluster", "utf8", "visNetwork", "XML", "xtable", "yaml"))
install.packages('ggraph')
install.packages('ggforce')
install.packages('units')
install.package('ggrpah')
install.package('ggraph')
install.packages('ggraph')
setwd("~/Dropbox/style/vocab_historical")
library(dplyr)
library(feather)
library(ggplot2)
library(quanteda)
library(readtext)
library(stringr)
counts <- read_feather('/home/paul/Dropbox/style/nodes_with_sw.feather')
counts <- read_feather('/home/paul/Dropbox/style/nodes_with_sw.feather')
colnames(counts) <- paste0('y', colnames(counts))
counts <- read_feather('/home/paul/Dropbox/style/nodes_with_sw.feather')
counts <- read_feather('/home/paul/Dropbox/style/nodes_with_sw.feather')
colnames(counts) <- paste0('y', colnames(counts))
tmp <- select(counts, '188' in colnames(counts))
tmp <- select(counts, '188' %in% colnames(counts))
tmp <- select(counts, starts_with('y188'), starts_with('y189'))
View(tmp)
tmp <- select(counts, starts_with('y188'), starts_with('y189'), 'yword')
View(tmp)
tmp <- select(counts, starts_with('y188'), starts_with('y189'))
?rowSums
t2 <- rowSums(tmp)
names(t2) <- counts$yword
t2['and']
corp <- readtext('../texts/Stevenson/*.txt', dvsep = "-",
docvarsfrom = "filenames",
docvarnames = c("title", "author", "year")) %>% corpus
t1 <- corpus_subset(corp, author=='Stevenson')
t1 <- texts(t1)
d1 <- dfm(t1, remove_numbers=TRUE, remove_punct=TRUE, remove_symbols=TRUE,remove_hyphens=TRUE) %>% t %>% data.frame
colnames(d1) <- 'count'
d1$word <- rownames(d1)
View(d1)
d1 <- dfm(t1, remove_numbers=TRUE, remove_punct=TRUE, remove_symbols=TRUE,remove_hyphens=TRUE) %>% t %>% data.frame
View(d1)
d1 <- dfm(t1, remove_numbers=TRUE, remove_punct=TRUE, remove_symbols=TRUE,remove_hyphens=TRUE) %>% t %>% data.frame
View(d1)
tw <- d1$document
d1 <- d1[-'document']
d1$document <- NULL
rls_counts <- rowSums(d1)
names(rls_counts) <- tw
rls_counts['the']
?write_feather
write_feather(rls_counts, 'rls_counts.feather')
save(rls_counts, 'rls_counts.feather')
rls_counts_df <- data.frame(rls_counts, tw)
View(rls_counts_df)
write_feather(rls_counts_df, 'rls_counts.feather')
base_counts_df <- data.frame(t2, names(t2))
base_counts_df <- data.frame(count=t2, word=names(t2)) %>% filter(count > 41)
View(base_counts_df)
base_counts_df <- data.frame(count=t2, word=names(t2)) #%>% filter(count > 41)
View(base_counts_df)
counts <- read_feather('/home/paul/Dropbox/style/nodes_with_sw.feather')
colnames(counts) <- paste0('y', colnames(counts))
tmp <- select(counts, starts_with('y188'), starts_with('y189'))
tmp[is.na(tmp)] <- 0
t2 <- rowSums(tmp)
names(t2) <- counts$yword
base_counts_df <- data.frame(count=t2, word=names(t2)) #%>% filter(count > 41)
View(base_counts_df)
base_counts_df <- data.frame(count=t2, word=names(t2)) %>% filter(count > 41)
View(base_counts_df)
base_counts_df <- data.frame(count=t2, word=names(t2)) %>% filter(count > 41)
write_feather(base_counts_df, 'base_counts.feather')
View(rls_counts_df)
rls_counts_df <- data.frame(count=rls_counts, word=tw)
rls_counts_df$rate <- rls_counts_df$count/sum(rls_counts_df)
rls_counts_df$rate <- rls_counts_df$count/sum(rls_counts_df$count)
View(rls_counts_df)
base_counts_df$rate <- base_counts_df$count/sum(base_counts_df$count)
View(base_counts_df)
View(rls_counts_df)
base_counts_df <- data.frame(base_count=t2, word=names(t2)) %>% filter(count > 41)
base_counts_df <- data.frame(base_count=t2, word=names(t2)) %>% filter(base_count > 41)
base_counts_df$base_rate <- base_counts_df$base_count/sum(base_counts_df$base_count)
write_feather(base_counts_df, 'base_counts.feather')
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count)
d1 <- dfm(t1, remove_numbers=TRUE, remove_punct=TRUE, remove_symbols=TRUE,remove_hyphens=TRUE) %>% t %>% data.frame
tw <- d1$document
rls_counts <- rowSums(d1)
names(rls_counts) <- tw
rls_counts_df <- data.frame(rls_count=rls_counts, word=tw)
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count)
write_feather(rls_counts_df, 'rls_counts.feather')
all_counts <- left_join(base_counts_df, rls_counts_df, by='word')
View(all_counts)
all_counts <- left_join(rls_counts_df, base_counts_df, by='word')
View(all_counts)
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count) * 1000
base_counts_df$base_rate <- base_counts_df$base_count/sum(base_counts_df$base_count) * 1000
all_counts <- left_join(rls_counts_df, base_counts_df, by='word')
View(all_counts)
options(scipen=999)
all_counts <- left_join(rls_counts_df, base_counts_df, by='word')
View(all_counts)
all_counts$rate_ratio <- log(rls_rate)/log(base_rate)
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count) * 1000
all_counts <- left_join(rls_counts_df, base_counts_df, by='word')
all_counts$rate_ratio <- log(rls_rate)/log(base_rate)
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count) * 1000
View(rls_counts_df)
all_counts$rate_ratio <- log(all_counts$rls_rate)/log(all_counts$base_rate)
counts$word <- counts$yword
View(all_counts)
all_counts$rate_ratio <- all_counts$rls_rate/all_counts$base_rate
View(all_counts)
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count) * 10000
base_counts_df$base_rate <- base_counts_df$base_count/sum(base_counts_df$base_count) * 10000
write_feather(base_counts_df, 'base_counts.feather')
write_feather(rls_counts_df, 'rls_counts.feather')
options(scipen=999)
all_counts <- left_join(rls_counts_df, base_counts_df, by='word')
all_counts$rate_ratio <- all_counts$rls_rate/all_counts$base_rate
View(all_counts)
rls_counts_df$rls_rate <- rls_counts_df$rls_count/sum(rls_counts_df$rls_count) * 10000
base_counts_df$base_rate <- base_counts_df$base_count/sum(base_counts_df$base_count) * 10000
options(scipen=999)
all_counts <- left_join(rls_counts_df, base_counts_df, by='word')
all_counts$rate_ratio <- all_counts$rls_rate/all_counts$base_rate
View(all_counts)
write_feather(all_counts, 'all_counts.feather')
setwd("~/Dropbox/style/vocab_historical/vocab-app")
all_counts <- read_feather('../data/all_counts.feather')
setwd("~/Dropbox/style/vocab_historical")
all_counts <- read_feather('../data/all_counts.feather')
shiny::runApp()
runApp()
runApp()
?sqrt
all_counts$error <- sqrt(all_counts$rls_count)*1.96
View(all_counts)
write_feather(all_counts, 'all_counts.feather')
View(all_counts)
all_counts$error <- sqrt(all_counts$rls_count)*1.96
write_feather(all_counts, 'all_counts.feather')
runApp()
runApp()
